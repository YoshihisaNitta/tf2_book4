{"cells":[{"cell_type":"markdown","id":"french-blackberry","metadata":{"id":"french-blackberry"},"source":["# 5.1\n","## Keras スタイルで CNN をプログラミングする (p.270)"]},{"cell_type":"code","execution_count":1,"id":"unusual-insulation","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"unusual-insulation","executionInfo":{"status":"ok","timestamp":1651382522495,"user_tz":-540,"elapsed":5955,"user":{"displayName":"Yoshihisa Nitta","userId":"15888006800030996813"}},"outputId":"b14d2d81-3a1a-4b0e-fb92-bef450744732"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 1s 0us/step\n","26435584/26421880 [==============================] - 1s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n"]}],"source":["# 5-01-9 Fashion-MNIST の読み込みと前処理\n","# p.270\n","\n","from tensorflow.keras import datasets\n","\n","(x_train, t_train), (x_test, t_test) = datasets.fashion_mnist.load_data()\n","\n","x_train = x_train / 255\n","x_test = x_test / 255\n","\n","# Reshape (-1, 28, 28) --> (-1, 28, 28, 1)\n","x_train = x_train.reshape(-1, 28, 28, 1)\n","x_test = x_test.reshape(-1, 28, 28, 1)"]},{"cell_type":"code","execution_count":2,"id":"transsexual-silence","metadata":{"id":"transsexual-silence","executionInfo":{"status":"ok","timestamp":1651382525877,"user_tz":-540,"elapsed":3385,"user":{"displayName":"Yoshihisa Nitta","userId":"15888006800030996813"}}},"outputs":[],"source":["# 5-01-10 CNN モデルの定義\n","# p.271-274\n","\n","from tensorflow.keras import models, layers, optimizers, regularizers\n","\n","model = models.Sequential()\n","\n","# 正則化の係数\n","weight_decay = 1e-4\n","\n","model.add(\n","    layers.Conv2D(\n","        filters=64,\n","        kernel_size=(3,3),\n","        input_shape=(28, 28, 1),\n","        padding='same',\n","        kernel_regularizer=regularizers.l2(weight_decay),\n","        activation='relu'\n","    ))\n","\n","model.add(\n","    layers.Conv2D(\n","        filters=32,\n","    kernel_size=(3, 3),\n","    padding='same',\n","    kernel_regularizer=regularizers.l2(weight_decay),\n","    activation='relu'\n","    ))\n","\n","model.add(\n","    layers.MaxPooling2D(\n","        pool_size=(2, 2)\n","    ))\n","\n","model.add(\n","    layers.Conv2D(\n","        filters=16,\n","        kernel_size=(3, 3),\n","        padding='same',\n","        kernel_regularizer=regularizers.l2(weight_decay),\n","        activation='relu'\n","    ))\n","\n","model.add(\n","    layers.MaxPooling2D(\n","        pool_size=(2, 2)\n","    ))\n","\n","model.add(layers.Dropout(0.4))\n","\n","model.add(layers.Flatten())\n","\n","model.add(\n","    layers.Dense(\n","        128,\n","        activation='relu'\n","    ))\n","\n","model.add(\n","    layers.Dense(\n","        10,\n","        activation='softmax'\n","    ))"]},{"cell_type":"code","execution_count":3,"id":"according-there","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"according-there","executionInfo":{"status":"ok","timestamp":1651382525877,"user_tz":-540,"elapsed":10,"user":{"displayName":"Yoshihisa Nitta","userId":"15888006800030996813"}},"outputId":"8ea2f5a2-8bdf-4bd1-c30c-8f75514a10e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 28, 28, 64)        640       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 28, 28, 32)        18464     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 14, 14, 16)        4624      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 7, 7, 16)         0         \n"," 2D)                                                             \n","                                                                 \n"," dropout (Dropout)           (None, 7, 7, 16)          0         \n","                                                                 \n"," flatten (Flatten)           (None, 784)               0         \n","                                                                 \n"," dense (Dense)               (None, 128)               100480    \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 125,498\n","Trainable params: 125,498\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]}],"source":["learning_rate = 0.1\n","\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=optimizers.SGD(lr=learning_rate),\n","    metrics=['accuracy']\n",")\n","\n","model.summary()"]},{"cell_type":"code","execution_count":4,"id":"express-breach","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"express-breach","executionInfo":{"status":"ok","timestamp":1651382855552,"user_tz":-540,"elapsed":329679,"user":{"displayName":"Yoshihisa Nitta","userId":"15888006800030996813"}},"outputId":"7a377771-d3d7-4592-85ca-df80617005c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","750/750 [==============================] - 13s 5ms/step - loss: 0.7090 - accuracy: 0.7369 - val_loss: 0.4515 - val_accuracy: 0.8364\n","Epoch 2/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.4397 - accuracy: 0.8399 - val_loss: 0.3732 - val_accuracy: 0.8648\n","Epoch 3/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.3796 - accuracy: 0.8633 - val_loss: 0.3196 - val_accuracy: 0.8867\n","Epoch 4/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.3405 - accuracy: 0.8763 - val_loss: 0.2907 - val_accuracy: 0.8975\n","Epoch 5/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.3194 - accuracy: 0.8846 - val_loss: 0.2910 - val_accuracy: 0.8951\n","Epoch 6/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.3020 - accuracy: 0.8918 - val_loss: 0.2706 - val_accuracy: 0.9005\n","Epoch 7/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2889 - accuracy: 0.8959 - val_loss: 0.2713 - val_accuracy: 0.9038\n","Epoch 8/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2804 - accuracy: 0.8989 - val_loss: 0.2497 - val_accuracy: 0.9097\n","Epoch 9/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2714 - accuracy: 0.9021 - val_loss: 0.2535 - val_accuracy: 0.9104\n","Epoch 10/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2642 - accuracy: 0.9064 - val_loss: 0.2449 - val_accuracy: 0.9148\n","Epoch 11/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2559 - accuracy: 0.9078 - val_loss: 0.2513 - val_accuracy: 0.9110\n","Epoch 12/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2491 - accuracy: 0.9116 - val_loss: 0.2436 - val_accuracy: 0.9136\n","Epoch 13/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2441 - accuracy: 0.9130 - val_loss: 0.2336 - val_accuracy: 0.9188\n","Epoch 14/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2404 - accuracy: 0.9144 - val_loss: 0.2354 - val_accuracy: 0.9172\n","Epoch 15/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2333 - accuracy: 0.9179 - val_loss: 0.2275 - val_accuracy: 0.9201\n","Epoch 16/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2307 - accuracy: 0.9189 - val_loss: 0.2290 - val_accuracy: 0.9202\n","Epoch 17/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2253 - accuracy: 0.9207 - val_loss: 0.2242 - val_accuracy: 0.9233\n","Epoch 18/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2225 - accuracy: 0.9226 - val_loss: 0.2389 - val_accuracy: 0.9164\n","Epoch 19/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2179 - accuracy: 0.9235 - val_loss: 0.2220 - val_accuracy: 0.9227\n","Epoch 20/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2154 - accuracy: 0.9231 - val_loss: 0.2210 - val_accuracy: 0.9233\n","Epoch 21/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2128 - accuracy: 0.9245 - val_loss: 0.2379 - val_accuracy: 0.9168\n","Epoch 22/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2079 - accuracy: 0.9272 - val_loss: 0.2156 - val_accuracy: 0.9276\n","Epoch 23/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2051 - accuracy: 0.9280 - val_loss: 0.2188 - val_accuracy: 0.9232\n","Epoch 24/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2035 - accuracy: 0.9291 - val_loss: 0.2225 - val_accuracy: 0.9237\n","Epoch 25/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2009 - accuracy: 0.9298 - val_loss: 0.2253 - val_accuracy: 0.9212\n","Epoch 26/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1985 - accuracy: 0.9307 - val_loss: 0.2180 - val_accuracy: 0.9262\n","Epoch 27/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1966 - accuracy: 0.9315 - val_loss: 0.2132 - val_accuracy: 0.9247\n","Epoch 28/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1936 - accuracy: 0.9322 - val_loss: 0.2156 - val_accuracy: 0.9274\n","Epoch 29/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1924 - accuracy: 0.9333 - val_loss: 0.2356 - val_accuracy: 0.9178\n","Epoch 30/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1889 - accuracy: 0.9344 - val_loss: 0.2146 - val_accuracy: 0.9269\n","Epoch 31/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1894 - accuracy: 0.9351 - val_loss: 0.2243 - val_accuracy: 0.9252\n","Epoch 32/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1835 - accuracy: 0.9377 - val_loss: 0.2161 - val_accuracy: 0.9293\n","Epoch 33/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1828 - accuracy: 0.9369 - val_loss: 0.2155 - val_accuracy: 0.9270\n","Epoch 34/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1819 - accuracy: 0.9374 - val_loss: 0.2187 - val_accuracy: 0.9278\n","Epoch 35/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1786 - accuracy: 0.9388 - val_loss: 0.2186 - val_accuracy: 0.9275\n","Epoch 36/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1795 - accuracy: 0.9383 - val_loss: 0.2096 - val_accuracy: 0.9299\n","Epoch 37/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1764 - accuracy: 0.9392 - val_loss: 0.2136 - val_accuracy: 0.9277\n","Epoch 38/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1733 - accuracy: 0.9404 - val_loss: 0.2189 - val_accuracy: 0.9277\n","Epoch 39/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1710 - accuracy: 0.9414 - val_loss: 0.2253 - val_accuracy: 0.9243\n","Epoch 40/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1686 - accuracy: 0.9420 - val_loss: 0.2207 - val_accuracy: 0.9281\n","Epoch 41/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1689 - accuracy: 0.9427 - val_loss: 0.2245 - val_accuracy: 0.9249\n","Epoch 42/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1681 - accuracy: 0.9429 - val_loss: 0.2232 - val_accuracy: 0.9290\n","Epoch 43/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1658 - accuracy: 0.9442 - val_loss: 0.2255 - val_accuracy: 0.9278\n","Epoch 44/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1657 - accuracy: 0.9450 - val_loss: 0.2216 - val_accuracy: 0.9266\n","Epoch 45/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1647 - accuracy: 0.9446 - val_loss: 0.2340 - val_accuracy: 0.9194\n","Epoch 46/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1597 - accuracy: 0.9462 - val_loss: 0.2213 - val_accuracy: 0.9280\n","Epoch 47/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1612 - accuracy: 0.9455 - val_loss: 0.2233 - val_accuracy: 0.9295\n","Epoch 48/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1611 - accuracy: 0.9443 - val_loss: 0.2287 - val_accuracy: 0.9267\n","Epoch 49/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1577 - accuracy: 0.9464 - val_loss: 0.2236 - val_accuracy: 0.9269\n","Epoch 50/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1578 - accuracy: 0.9475 - val_loss: 0.2285 - val_accuracy: 0.9282\n","Epoch 51/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1536 - accuracy: 0.9493 - val_loss: 0.2213 - val_accuracy: 0.9291\n","Epoch 52/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1553 - accuracy: 0.9482 - val_loss: 0.2170 - val_accuracy: 0.9302\n","Epoch 53/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1549 - accuracy: 0.9482 - val_loss: 0.2153 - val_accuracy: 0.9308\n","Epoch 54/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1536 - accuracy: 0.9489 - val_loss: 0.2106 - val_accuracy: 0.9314\n","Epoch 55/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1517 - accuracy: 0.9497 - val_loss: 0.2143 - val_accuracy: 0.9330\n","Epoch 56/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1494 - accuracy: 0.9507 - val_loss: 0.2384 - val_accuracy: 0.9237\n","Epoch 57/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1508 - accuracy: 0.9505 - val_loss: 0.2190 - val_accuracy: 0.9302\n","Epoch 58/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1498 - accuracy: 0.9505 - val_loss: 0.2248 - val_accuracy: 0.9280\n","Epoch 59/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1451 - accuracy: 0.9517 - val_loss: 0.2329 - val_accuracy: 0.9282\n","Epoch 60/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1436 - accuracy: 0.9535 - val_loss: 0.2196 - val_accuracy: 0.9308\n","Epoch 61/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1454 - accuracy: 0.9529 - val_loss: 0.2270 - val_accuracy: 0.9310\n","Epoch 62/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1418 - accuracy: 0.9536 - val_loss: 0.2264 - val_accuracy: 0.9308\n","Epoch 63/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1421 - accuracy: 0.9534 - val_loss: 0.2238 - val_accuracy: 0.9289\n","Epoch 64/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1410 - accuracy: 0.9538 - val_loss: 0.2169 - val_accuracy: 0.9312\n","Epoch 65/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1420 - accuracy: 0.9535 - val_loss: 0.2233 - val_accuracy: 0.9300\n","Epoch 66/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1419 - accuracy: 0.9525 - val_loss: 0.2244 - val_accuracy: 0.9283\n","Epoch 67/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1412 - accuracy: 0.9539 - val_loss: 0.2280 - val_accuracy: 0.9317\n","Epoch 68/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1408 - accuracy: 0.9555 - val_loss: 0.2237 - val_accuracy: 0.9282\n","Epoch 69/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1370 - accuracy: 0.9560 - val_loss: 0.2331 - val_accuracy: 0.9306\n","Epoch 70/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1372 - accuracy: 0.9545 - val_loss: 0.2338 - val_accuracy: 0.9301\n","Epoch 71/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1359 - accuracy: 0.9563 - val_loss: 0.2328 - val_accuracy: 0.9280\n","Epoch 72/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1365 - accuracy: 0.9559 - val_loss: 0.2259 - val_accuracy: 0.9321\n","Epoch 73/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1365 - accuracy: 0.9562 - val_loss: 0.2339 - val_accuracy: 0.9298\n","Epoch 74/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1352 - accuracy: 0.9567 - val_loss: 0.2255 - val_accuracy: 0.9301\n","Epoch 75/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1370 - accuracy: 0.9557 - val_loss: 0.2242 - val_accuracy: 0.9283\n","Epoch 76/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1317 - accuracy: 0.9582 - val_loss: 0.2442 - val_accuracy: 0.9287\n","Epoch 77/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1317 - accuracy: 0.9577 - val_loss: 0.2252 - val_accuracy: 0.9307\n","Epoch 78/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1303 - accuracy: 0.9583 - val_loss: 0.2270 - val_accuracy: 0.9317\n","Epoch 79/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1337 - accuracy: 0.9578 - val_loss: 0.2283 - val_accuracy: 0.9323\n","Epoch 80/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1302 - accuracy: 0.9592 - val_loss: 0.2362 - val_accuracy: 0.9292\n","Epoch 81/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1270 - accuracy: 0.9604 - val_loss: 0.2267 - val_accuracy: 0.9290\n","Epoch 82/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1294 - accuracy: 0.9586 - val_loss: 0.2278 - val_accuracy: 0.9295\n","Epoch 83/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1294 - accuracy: 0.9589 - val_loss: 0.2318 - val_accuracy: 0.9298\n","Epoch 84/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1273 - accuracy: 0.9603 - val_loss: 0.2305 - val_accuracy: 0.9283\n","Epoch 85/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1262 - accuracy: 0.9611 - val_loss: 0.2331 - val_accuracy: 0.9294\n","Epoch 86/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1259 - accuracy: 0.9609 - val_loss: 0.2340 - val_accuracy: 0.9304\n","Epoch 87/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1272 - accuracy: 0.9601 - val_loss: 0.2367 - val_accuracy: 0.9304\n","Epoch 88/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1247 - accuracy: 0.9613 - val_loss: 0.2461 - val_accuracy: 0.9315\n","Epoch 89/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1268 - accuracy: 0.9611 - val_loss: 0.2424 - val_accuracy: 0.9302\n","Epoch 90/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1240 - accuracy: 0.9606 - val_loss: 0.2313 - val_accuracy: 0.9317\n","Epoch 91/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1250 - accuracy: 0.9615 - val_loss: 0.2288 - val_accuracy: 0.9327\n","Epoch 92/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1253 - accuracy: 0.9610 - val_loss: 0.2358 - val_accuracy: 0.9298\n","Epoch 93/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1226 - accuracy: 0.9624 - val_loss: 0.2349 - val_accuracy: 0.9296\n","Epoch 94/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1222 - accuracy: 0.9620 - val_loss: 0.2450 - val_accuracy: 0.9255\n","Epoch 95/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1225 - accuracy: 0.9615 - val_loss: 0.2261 - val_accuracy: 0.9293\n","Epoch 96/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1219 - accuracy: 0.9621 - val_loss: 0.2453 - val_accuracy: 0.9276\n","Epoch 97/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1196 - accuracy: 0.9633 - val_loss: 0.2317 - val_accuracy: 0.9316\n","Epoch 98/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1199 - accuracy: 0.9634 - val_loss: 0.2324 - val_accuracy: 0.9323\n","Epoch 99/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1190 - accuracy: 0.9629 - val_loss: 0.2366 - val_accuracy: 0.9288\n","Epoch 100/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1187 - accuracy: 0.9644 - val_loss: 0.2353 - val_accuracy: 0.9281\n"]}],"source":["# 5-01-11 CNN モデルによる学習の実行\n","# p.276\n","\n","epoch = 100\n","batch_size = 64\n","\n","history = model.fit(\n","    x_train,\n","    t_train,\n","    batch_size=batch_size,\n","    epochs=epoch,\n","    verbose=1,\n","    validation_split=0.2,\n","    shuffle=True\n",")"]},{"cell_type":"code","execution_count":5,"id":"opposite-converter","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"opposite-converter","executionInfo":{"status":"ok","timestamp":1651382856556,"user_tz":-540,"elapsed":1007,"user":{"displayName":"Yoshihisa Nitta","userId":"15888006800030996813"}},"outputId":"664ab654-fda1-404e-bca9-3a882fe84ac5"},"outputs":[{"output_type":"stream","name":"stdout","text":["test_loss: 0.2584  test_acc: 0.9256\n"]}],"source":["# 5-01-12 テストデータによる学習済みモデルの評価\n","# p.277\n","\n","test_loss, test_acc = model.evaluate(x_test, t_test, verbose=0)\n","print(f'test_loss: {test_loss:.4f}  test_acc: {test_acc:.4f}')"]},{"cell_type":"markdown","id":"exempt-recall","metadata":{"id":"exempt-recall"},"source":["# [自習] Keras の Functional API で記述する"]},{"cell_type":"code","execution_count":6,"id":"latter-moment","metadata":{"id":"latter-moment","executionInfo":{"status":"ok","timestamp":1651382856556,"user_tz":-540,"elapsed":7,"user":{"displayName":"Yoshihisa Nitta","userId":"15888006800030996813"}}},"outputs":[],"source":["# 5-01-10 CNN モデルの定義\n","# p.271-274\n","\n","import tensorflow as tf\n","from tensorflow.keras import optimizers, regularizers\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n","\n","input = tf.keras.Input(shape=(28,28,1), dtype='float32')\n","\n","# 正則化の係数\n","weight_decay = 1e-4\n","\n","H = Conv2D(\n","        filters=64,\n","        kernel_size=(3,3),\n","        padding='same',\n","        kernel_regularizer=regularizers.l2(weight_decay),\n","        activation='relu'\n","        )(input)\n","\n","H = Conv2D(\n","        filters=32,\n","        kernel_size=(3, 3),\n","        padding='same',\n","        kernel_regularizer=regularizers.l2(weight_decay),\n","        activation='relu'\n","        )(H)\n","\n","H = MaxPooling2D(pool_size=(2, 2))(H)\n","\n","H = Conv2D(\n","        filters=16,\n","        kernel_size=(3, 3),\n","        padding='same',\n","        kernel_regularizer=regularizers.l2(weight_decay),\n","        activation='relu'\n","        )(H)\n","\n","H = MaxPooling2D(pool_size=(2, 2))(H)\n","\n","H = Dropout(0.4)(H)\n","\n","H = Flatten()(H)\n","\n","H = Dense(128, activation='relu')(H)\n","\n","H = Dense(10,activation='softmax')(H)\n","\n","model2 = tf.keras.Model(inputs=input, outputs=H)"]},{"cell_type":"code","execution_count":7,"id":"outdoor-family","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"outdoor-family","executionInfo":{"status":"ok","timestamp":1651382856557,"user_tz":-540,"elapsed":7,"user":{"displayName":"Yoshihisa Nitta","userId":"15888006800030996813"}},"outputId":"9afe0d1a-ba99-4220-9760-3638e0f681cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 28, 28, 64)        640       \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 28, 28, 32)        18464     \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 14, 14, 16)        4624      \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 7, 7, 16)         0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 7, 7, 16)          0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 128)               100480    \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 125,498\n","Trainable params: 125,498\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]}],"source":["learning_rate = 0.1\n","\n","model2.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=optimizers.SGD(lr=learning_rate),\n","    metrics=['accuracy']\n",")\n","\n","model2.summary()"]},{"cell_type":"code","execution_count":8,"id":"optional-scholar","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"optional-scholar","executionInfo":{"status":"ok","timestamp":1651383179284,"user_tz":-540,"elapsed":322730,"user":{"displayName":"Yoshihisa Nitta","userId":"15888006800030996813"}},"outputId":"45d2bd69-8e6b-4ecb-fce9-ec3a5a8f5f68"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","750/750 [==============================] - 4s 5ms/step - loss: 0.7273 - accuracy: 0.7302 - val_loss: 0.4422 - val_accuracy: 0.8348\n","Epoch 2/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.4413 - accuracy: 0.8422 - val_loss: 0.3653 - val_accuracy: 0.8673\n","Epoch 3/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.3862 - accuracy: 0.8622 - val_loss: 0.3294 - val_accuracy: 0.8812\n","Epoch 4/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.3557 - accuracy: 0.8713 - val_loss: 0.3010 - val_accuracy: 0.8921\n","Epoch 5/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.3322 - accuracy: 0.8818 - val_loss: 0.2856 - val_accuracy: 0.8982\n","Epoch 6/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.3177 - accuracy: 0.8863 - val_loss: 0.2802 - val_accuracy: 0.8983\n","Epoch 7/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.3026 - accuracy: 0.8911 - val_loss: 0.3010 - val_accuracy: 0.8896\n","Epoch 8/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2941 - accuracy: 0.8953 - val_loss: 0.2605 - val_accuracy: 0.9072\n","Epoch 9/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2834 - accuracy: 0.8992 - val_loss: 0.2582 - val_accuracy: 0.9049\n","Epoch 10/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2756 - accuracy: 0.9015 - val_loss: 0.2509 - val_accuracy: 0.9114\n","Epoch 11/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2690 - accuracy: 0.9040 - val_loss: 0.2717 - val_accuracy: 0.8995\n","Epoch 12/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2584 - accuracy: 0.9077 - val_loss: 0.2687 - val_accuracy: 0.9023\n","Epoch 13/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2549 - accuracy: 0.9100 - val_loss: 0.2494 - val_accuracy: 0.9108\n","Epoch 14/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2493 - accuracy: 0.9126 - val_loss: 0.2295 - val_accuracy: 0.9202\n","Epoch 15/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2419 - accuracy: 0.9146 - val_loss: 0.2337 - val_accuracy: 0.9167\n","Epoch 16/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2376 - accuracy: 0.9160 - val_loss: 0.2369 - val_accuracy: 0.9141\n","Epoch 17/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2334 - accuracy: 0.9177 - val_loss: 0.2290 - val_accuracy: 0.9190\n","Epoch 18/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2274 - accuracy: 0.9199 - val_loss: 0.2306 - val_accuracy: 0.9180\n","Epoch 19/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2233 - accuracy: 0.9223 - val_loss: 0.2280 - val_accuracy: 0.9194\n","Epoch 20/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2226 - accuracy: 0.9231 - val_loss: 0.2241 - val_accuracy: 0.9211\n","Epoch 21/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2206 - accuracy: 0.9230 - val_loss: 0.2276 - val_accuracy: 0.9208\n","Epoch 22/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2140 - accuracy: 0.9246 - val_loss: 0.2178 - val_accuracy: 0.9252\n","Epoch 23/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2080 - accuracy: 0.9271 - val_loss: 0.2182 - val_accuracy: 0.9255\n","Epoch 24/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2103 - accuracy: 0.9272 - val_loss: 0.2166 - val_accuracy: 0.9257\n","Epoch 25/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2059 - accuracy: 0.9294 - val_loss: 0.2189 - val_accuracy: 0.9240\n","Epoch 26/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2031 - accuracy: 0.9302 - val_loss: 0.2155 - val_accuracy: 0.9251\n","Epoch 27/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1998 - accuracy: 0.9310 - val_loss: 0.2126 - val_accuracy: 0.9275\n","Epoch 28/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.2000 - accuracy: 0.9309 - val_loss: 0.2122 - val_accuracy: 0.9286\n","Epoch 29/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1957 - accuracy: 0.9319 - val_loss: 0.2138 - val_accuracy: 0.9293\n","Epoch 30/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1936 - accuracy: 0.9336 - val_loss: 0.2234 - val_accuracy: 0.9252\n","Epoch 31/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1906 - accuracy: 0.9342 - val_loss: 0.2283 - val_accuracy: 0.9218\n","Epoch 32/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1894 - accuracy: 0.9333 - val_loss: 0.2194 - val_accuracy: 0.9265\n","Epoch 33/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1879 - accuracy: 0.9352 - val_loss: 0.2190 - val_accuracy: 0.9253\n","Epoch 34/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1835 - accuracy: 0.9384 - val_loss: 0.2159 - val_accuracy: 0.9283\n","Epoch 35/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1811 - accuracy: 0.9383 - val_loss: 0.2183 - val_accuracy: 0.9249\n","Epoch 36/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1827 - accuracy: 0.9377 - val_loss: 0.2199 - val_accuracy: 0.9253\n","Epoch 37/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1803 - accuracy: 0.9384 - val_loss: 0.2181 - val_accuracy: 0.9279\n","Epoch 38/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1771 - accuracy: 0.9391 - val_loss: 0.2167 - val_accuracy: 0.9283\n","Epoch 39/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1733 - accuracy: 0.9416 - val_loss: 0.2172 - val_accuracy: 0.9282\n","Epoch 40/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1760 - accuracy: 0.9400 - val_loss: 0.2104 - val_accuracy: 0.9290\n","Epoch 41/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1723 - accuracy: 0.9414 - val_loss: 0.2214 - val_accuracy: 0.9265\n","Epoch 42/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1714 - accuracy: 0.9414 - val_loss: 0.2245 - val_accuracy: 0.9227\n","Epoch 43/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1691 - accuracy: 0.9419 - val_loss: 0.2157 - val_accuracy: 0.9286\n","Epoch 44/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1676 - accuracy: 0.9438 - val_loss: 0.2173 - val_accuracy: 0.9284\n","Epoch 45/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1664 - accuracy: 0.9436 - val_loss: 0.2187 - val_accuracy: 0.9277\n","Epoch 46/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1627 - accuracy: 0.9455 - val_loss: 0.2181 - val_accuracy: 0.9276\n","Epoch 47/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1616 - accuracy: 0.9455 - val_loss: 0.2214 - val_accuracy: 0.9277\n","Epoch 48/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1593 - accuracy: 0.9464 - val_loss: 0.2167 - val_accuracy: 0.9312\n","Epoch 49/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1610 - accuracy: 0.9464 - val_loss: 0.2225 - val_accuracy: 0.9277\n","Epoch 50/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1582 - accuracy: 0.9476 - val_loss: 0.2210 - val_accuracy: 0.9284\n","Epoch 51/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1589 - accuracy: 0.9480 - val_loss: 0.2207 - val_accuracy: 0.9288\n","Epoch 52/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1550 - accuracy: 0.9489 - val_loss: 0.2171 - val_accuracy: 0.9319\n","Epoch 53/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1577 - accuracy: 0.9474 - val_loss: 0.2267 - val_accuracy: 0.9277\n","Epoch 54/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1564 - accuracy: 0.9478 - val_loss: 0.2174 - val_accuracy: 0.9275\n","Epoch 55/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1535 - accuracy: 0.9494 - val_loss: 0.2212 - val_accuracy: 0.9307\n","Epoch 56/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1546 - accuracy: 0.9488 - val_loss: 0.2231 - val_accuracy: 0.9293\n","Epoch 57/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1528 - accuracy: 0.9496 - val_loss: 0.2253 - val_accuracy: 0.9282\n","Epoch 58/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1496 - accuracy: 0.9511 - val_loss: 0.2216 - val_accuracy: 0.9299\n","Epoch 59/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1503 - accuracy: 0.9503 - val_loss: 0.2210 - val_accuracy: 0.9293\n","Epoch 60/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1492 - accuracy: 0.9515 - val_loss: 0.2205 - val_accuracy: 0.9287\n","Epoch 61/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1454 - accuracy: 0.9523 - val_loss: 0.2263 - val_accuracy: 0.9277\n","Epoch 62/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1467 - accuracy: 0.9519 - val_loss: 0.2185 - val_accuracy: 0.9284\n","Epoch 63/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1461 - accuracy: 0.9522 - val_loss: 0.2195 - val_accuracy: 0.9289\n","Epoch 64/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1441 - accuracy: 0.9539 - val_loss: 0.2246 - val_accuracy: 0.9291\n","Epoch 65/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1451 - accuracy: 0.9515 - val_loss: 0.2249 - val_accuracy: 0.9275\n","Epoch 66/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1439 - accuracy: 0.9527 - val_loss: 0.2324 - val_accuracy: 0.9262\n","Epoch 67/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1422 - accuracy: 0.9541 - val_loss: 0.2236 - val_accuracy: 0.9317\n","Epoch 68/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1398 - accuracy: 0.9557 - val_loss: 0.2226 - val_accuracy: 0.9281\n","Epoch 69/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1390 - accuracy: 0.9553 - val_loss: 0.2375 - val_accuracy: 0.9294\n","Epoch 70/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1439 - accuracy: 0.9528 - val_loss: 0.2251 - val_accuracy: 0.9326\n","Epoch 71/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1384 - accuracy: 0.9559 - val_loss: 0.2263 - val_accuracy: 0.9307\n","Epoch 72/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1356 - accuracy: 0.9574 - val_loss: 0.2267 - val_accuracy: 0.9308\n","Epoch 73/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1378 - accuracy: 0.9557 - val_loss: 0.2340 - val_accuracy: 0.9264\n","Epoch 74/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1377 - accuracy: 0.9550 - val_loss: 0.2365 - val_accuracy: 0.9284\n","Epoch 75/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1362 - accuracy: 0.9559 - val_loss: 0.2350 - val_accuracy: 0.9288\n","Epoch 76/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1339 - accuracy: 0.9573 - val_loss: 0.2326 - val_accuracy: 0.9318\n","Epoch 77/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1348 - accuracy: 0.9564 - val_loss: 0.2361 - val_accuracy: 0.9262\n","Epoch 78/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1348 - accuracy: 0.9566 - val_loss: 0.2334 - val_accuracy: 0.9289\n","Epoch 79/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1326 - accuracy: 0.9580 - val_loss: 0.2371 - val_accuracy: 0.9264\n","Epoch 80/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1306 - accuracy: 0.9589 - val_loss: 0.2280 - val_accuracy: 0.9275\n","Epoch 81/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1317 - accuracy: 0.9586 - val_loss: 0.2308 - val_accuracy: 0.9303\n","Epoch 82/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1323 - accuracy: 0.9571 - val_loss: 0.2309 - val_accuracy: 0.9307\n","Epoch 83/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1308 - accuracy: 0.9592 - val_loss: 0.2282 - val_accuracy: 0.9288\n","Epoch 84/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1291 - accuracy: 0.9591 - val_loss: 0.2337 - val_accuracy: 0.9321\n","Epoch 85/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1299 - accuracy: 0.9586 - val_loss: 0.2266 - val_accuracy: 0.9298\n","Epoch 86/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1301 - accuracy: 0.9589 - val_loss: 0.2438 - val_accuracy: 0.9251\n","Epoch 87/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1280 - accuracy: 0.9604 - val_loss: 0.2310 - val_accuracy: 0.9300\n","Epoch 88/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1287 - accuracy: 0.9597 - val_loss: 0.2377 - val_accuracy: 0.9312\n","Epoch 89/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1270 - accuracy: 0.9610 - val_loss: 0.2378 - val_accuracy: 0.9301\n","Epoch 90/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1261 - accuracy: 0.9595 - val_loss: 0.2346 - val_accuracy: 0.9302\n","Epoch 91/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1258 - accuracy: 0.9599 - val_loss: 0.2358 - val_accuracy: 0.9302\n","Epoch 92/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1249 - accuracy: 0.9605 - val_loss: 0.2439 - val_accuracy: 0.9273\n","Epoch 93/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1261 - accuracy: 0.9602 - val_loss: 0.2314 - val_accuracy: 0.9286\n","Epoch 94/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1242 - accuracy: 0.9610 - val_loss: 0.2362 - val_accuracy: 0.9313\n","Epoch 95/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1235 - accuracy: 0.9619 - val_loss: 0.2438 - val_accuracy: 0.9278\n","Epoch 96/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1243 - accuracy: 0.9618 - val_loss: 0.2444 - val_accuracy: 0.9257\n","Epoch 97/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1264 - accuracy: 0.9610 - val_loss: 0.2292 - val_accuracy: 0.9293\n","Epoch 98/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1205 - accuracy: 0.9631 - val_loss: 0.2346 - val_accuracy: 0.9314\n","Epoch 99/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1230 - accuracy: 0.9619 - val_loss: 0.2346 - val_accuracy: 0.9298\n","Epoch 100/100\n","750/750 [==============================] - 3s 4ms/step - loss: 0.1223 - accuracy: 0.9621 - val_loss: 0.2401 - val_accuracy: 0.9298\n"]}],"source":["epoch = 100\n","batch_size = 64\n","\n","history = model2.fit(\n","    x_train,\n","    t_train,\n","    batch_size=batch_size,\n","    epochs=epoch,\n","    verbose=1,\n","    validation_split=0.2,\n","    shuffle=True\n",")"]},{"cell_type":"code","execution_count":9,"id":"fundamental-tomato","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fundamental-tomato","executionInfo":{"status":"ok","timestamp":1651383180697,"user_tz":-540,"elapsed":1416,"user":{"displayName":"Yoshihisa Nitta","userId":"15888006800030996813"}},"outputId":"cb25c49c-34b2-43f3-f6b6-b9ef439e38cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["test_loss: 0.2563  test_acc: 0.9249\n"]}],"source":["test_loss, test_acc = model2.evaluate(x_test, t_test, verbose=0)\n","print(f'test_loss: {test_loss:.4f}  test_acc: {test_acc:.4f}')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.12"},"colab":{"name":"tf2_book4_ch05_01b.ipynb","provenance":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}